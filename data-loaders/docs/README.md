# Data Loaders

This directory contains scripts and configurations for loading data into the DataOps Assistant PostgreSQL database.

## ğŸ“ Directory Structure

```
data-loaders/
â”œâ”€â”€ scripts/                    # Executable scripts
â”‚   â”œâ”€â”€ load_bank_data.py      # Main bank data loader (Python)
â”‚   â”œâ”€â”€ load_bank_data.sh      # Shell wrapper script
â”‚   â”œâ”€â”€ check_db_state.py      # Database state checker
â”‚   â””â”€â”€ verify_dbeaver_connection.py  # DBeaver connection helper
â”œâ”€â”€ config/                     # Configuration files
â”‚   â””â”€â”€ database.yml           # Database configuration
â”œâ”€â”€ requirements/               # Python dependencies
â”‚   â””â”€â”€ requirements.txt       # Required packages
â”œâ”€â”€ logs/                      # Log files (created automatically)
â””â”€â”€ docs/                      # Documentation
    â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### Option 1: Using Shell Script (Recommended)

```bash
cd data-loaders/scripts
./load_bank_data.sh
```

### Option 2: Using Python Directly

```bash
cd data-loaders/scripts
pip3 install -r ../requirements/requirements.txt
python3 load_bank_data.py --csv-file ../../data/bank_transactions.csv
```

## ğŸ“Š Available Scripts

### 1. Bank Data Loader (`load_bank_data.py`)

**Purpose:** Load bank transaction CSV data into PostgreSQL with validation and error handling.

**Features:**

- âœ… Data validation and cleaning
- ğŸ”„ Batch processing for large files
- ğŸš« Duplicate handling (skip or update)
- ğŸ“ˆ Progress tracking and statistics
- ğŸ”„ Error recovery and logging
- ğŸ—ƒï¸ Automatic table creation with indexes

**Usage:**

```bash
# Test connection
python3 load_bank_data.py --test-connection

# Load data (skip duplicates)
python3 load_bank_data.py --csv-file ../../data/bank_transactions.csv

# Update existing records
python3 load_bank_data.py --csv-file ../../data/bank_transactions.csv --update-duplicates

# Drop and recreate table
python3 load_bank_data.py --csv-file ../../data/bank_transactions.csv --drop-table

# Custom batch size
python3 load_bank_data.py --csv-file ../../data/bank_transactions.csv --batch-size 500
```

### 2. Shell Wrapper (`load_bank_data.sh`)

**Purpose:** Automated script with environment checks and setup.

**What it does:**

- ğŸ³ Checks Docker status
- ğŸ—„ï¸ Starts PostgreSQL container if needed
- ğŸ“¦ Installs Python dependencies
- ğŸ”Œ Tests database connection
- ğŸ“Š Loads data with progress feedback

### 3. Database State Checker (`check_db_state.py`)

**Purpose:** Quick verification of database contents.

**Shows:**

- ğŸ“Š Record counts
- ğŸ“‹ Sample data
- ğŸ“ˆ Database statistics
- ğŸ” Duplicate detection

### 4. DBeaver Connection Helper (`verify_dbeaver_connection.py`)

**Purpose:** Troubleshoot DBeaver connection issues.

**Provides:**

- ğŸ”— Connection verification
- ğŸ“ Schema and table listing
- ğŸ“Š Sample data preview
- ğŸ”§ Troubleshooting tips

## âš™ï¸ Configuration

### Environment Variables

The scripts use these environment variables from `../../.env`:

```
POSTGRES_DB=dataops_db
POSTGRES_USER=dataops_user
POSTGRES_PASSWORD=dataops_password
DB_HOST=localhost
DB_PORT=5432
```

### Database Configuration (`config/database.yml`)

- Connection settings
- Pool configuration
- Loading parameters
- Table schemas and constraints

## ğŸ“‹ Database Schema

The `bank_transactions` table is created with:

```sql
CREATE TABLE bank_transactions (
    id SERIAL PRIMARY KEY,
    transaction_id VARCHAR(50) UNIQUE NOT NULL,
    user_id INTEGER,
    account_id INTEGER,
    transaction_date DATE,
    transaction_time TIME,
    amount DECIMAL(12,2),
    currency VARCHAR(3),
    merchant VARCHAR(100),
    category VARCHAR(50),
    transaction_type VARCHAR(20),
    status VARCHAR(20),
    location VARCHAR(100),
    device VARCHAR(20),
    balance_after DECIMAL(12,2),
    notes TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes created for performance:**

- `user_id`
- `account_id`
- `transaction_date`
- `merchant`
- `category`
- `status`

## ğŸ”§ Troubleshooting

### Common Issues

1. **"Connection refused" Error**

   ```bash
   # Check if PostgreSQL is running
   docker-compose ps postgres

   # Start if needed
   docker-compose up -d postgres
   ```

2. **"Permission denied" Error**

   ```bash
   # Make shell script executable
   chmod +x load_bank_data.sh
   ```

3. **"Module not found" Error**

   ```bash
   # Install dependencies
   pip3 install -r requirements/requirements.txt
   ```

4. **"All records skipped" Message**
   - Data already exists (normal behavior)
   - Use `--update-duplicates` to update existing records
   - Use `--drop-table` to start fresh

### Logs

- Log files are created in `logs/data_loader.log`
- Includes timestamps, error details, and statistics
- Rotated automatically when they get large

## ğŸ“ˆ Performance Tips

1. **Batch Size:** Adjust `--batch-size` based on memory (default: 1000)
2. **Large Files:** Use smaller batch sizes for very large CSV files
3. **Network:** Run on same machine as PostgreSQL for best performance
4. **Indexes:** Indexes are created automatically for query optimization

## ğŸ”’ Security Notes

- Database credentials are loaded from `.env` file
- Never commit `.env` file to version control
- Use strong passwords in production
- Consider using connection pooling for high-volume loads

## ğŸ“ Support

If you encounter issues:

1. Check the logs in `logs/data_loader.log`
2. Run the database state checker: `python3 check_db_state.py`
3. Verify DBeaver connection: `python3 verify_dbeaver_connection.py`
4. Check Docker containers: `docker-compose ps`
